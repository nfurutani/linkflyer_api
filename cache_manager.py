import time
import json
import hashlib
import os
from typing import Dict, Optional, Any
from datetime import datetime, timedelta

class CacheManager:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    BigQueryã®çµæœã¨APIå‘¼ã³å‡ºã—çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    """
    
    def __init__(self, cache_dir: str = "cache", default_ttl: int = 3600):
        """
        Args:
            cache_dir: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            default_ttl: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰
        """
        self.cache_dir = cache_dir
        self.default_ttl = default_ttl
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
    
    def _generate_cache_key(self, key_data: str) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ"""
        return hashlib.md5(key_data.encode('utf-8')).hexdigest()
    
    def _get_cache_path(self, cache_key: str) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        return os.path.join(self.cache_dir, f"{cache_key}.json")
    
    def get(self, key: str, category: str = "general") -> Optional[Dict]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            category: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆbigquery, api, geminiç­‰ï¼‰
        
        Returns:
            ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯None
        """
        cache_key = self._generate_cache_key(f"{category}:{key}")
        cache_path = self._get_cache_path(cache_key)
        
        if not os.path.exists(cache_path):
            return None
        
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # TTLãƒã‚§ãƒƒã‚¯
            if cache_data.get('expires_at'):
                expires_at = datetime.fromisoformat(cache_data['expires_at'])
                if datetime.now() > expires_at:
                    # æœŸé™åˆ‡ã‚Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
                    os.unlink(cache_path)
                    return None
            
            print(f"ğŸ”„ Cache hit: {category}:{key}")
            return cache_data.get('data')
            
        except Exception as e:
            print(f"âš ï¸ Cache read error: {e}")
            # ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            try:
                os.unlink(cache_path)
            except:
                pass
            return None
    
    def set(self, key: str, data: Any, category: str = "general", ttl: Optional[int] = None) -> None:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        
        Args:
            key: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼
            data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            category: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚«ãƒ†ã‚´ãƒª
            ttl: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æœŸé™ï¼ˆç§’ï¼‰ã€Noneã®å ´åˆã¯default_ttlã‚’ä½¿ç”¨
        """
        cache_key = self._generate_cache_key(f"{category}:{key}")
        cache_path = self._get_cache_path(cache_key)
        
        if ttl is None:
            ttl = self.default_ttl
        
        expires_at = datetime.now() + timedelta(seconds=ttl)
        
        cache_data = {
            'data': data,
            'created_at': datetime.now().isoformat(),
            'expires_at': expires_at.isoformat(),
            'ttl': ttl,
            'key': key,
            'category': category
        }
        
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ’¾ Cached: {category}:{key} (TTL: {ttl}s)")
            
        except Exception as e:
            print(f"âš ï¸ Cache write error: {e}")
    
    def clear_category(self, category: str) -> int:
        """æŒ‡å®šã‚«ãƒ†ã‚´ãƒªã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        cleared_count = 0
        
        for filename in os.listdir(self.cache_dir):
            if filename.endswith('.json'):
                cache_path = os.path.join(self.cache_dir, filename)
                try:
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    
                    if cache_data.get('category') == category:
                        os.unlink(cache_path)
                        cleared_count += 1
                        
                except Exception:
                    pass
        
        print(f"ğŸ—‘ï¸ Cleared {cleared_count} cache entries for category: {category}")
        return cleared_count
    
    def clear_expired(self) -> int:
        """æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        cleared_count = 0
        now = datetime.now()
        
        for filename in os.listdir(self.cache_dir):
            if filename.endswith('.json'):
                cache_path = os.path.join(self.cache_dir, filename)
                try:
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    
                    if cache_data.get('expires_at'):
                        expires_at = datetime.fromisoformat(cache_data['expires_at'])
                        if now > expires_at:
                            os.unlink(cache_path)
                            cleared_count += 1
                            
                except Exception:
                    # èª­ã¿è¾¼ã‚ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤
                    try:
                        os.unlink(cache_path)
                        cleared_count += 1
                    except:
                        pass
        
        print(f"ğŸ—‘ï¸ Cleared {cleared_count} expired cache entries")
        return cleared_count
    
    def clear_all(self) -> int:
        """å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        cleared_count = 0
        
        for filename in os.listdir(self.cache_dir):
            if filename.endswith('.json'):
                cache_path = os.path.join(self.cache_dir, filename)
                try:
                    os.unlink(cache_path)
                    cleared_count += 1
                except Exception:
                    pass
        
        print(f"ğŸ—‘ï¸ Cleared all {cleared_count} cache entries")
        return cleared_count
    
    def get_stats(self) -> Dict:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        stats = {
            'total_files': 0,
            'categories': {},
            'total_size_bytes': 0,
            'expired_count': 0
        }
        
        now = datetime.now()
        
        for filename in os.listdir(self.cache_dir):
            if filename.endswith('.json'):
                cache_path = os.path.join(self.cache_dir, filename)
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
                    stats['total_size_bytes'] += os.path.getsize(cache_path)
                    stats['total_files'] += 1
                    
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    
                    category = cache_data.get('category', 'unknown')
                    if category not in stats['categories']:
                        stats['categories'][category] = 0
                    stats['categories'][category] += 1
                    
                    # æœŸé™åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯
                    if cache_data.get('expires_at'):
                        expires_at = datetime.fromisoformat(cache_data['expires_at'])
                        if now > expires_at:
                            stats['expired_count'] += 1
                            
                except Exception:
                    pass
        
        stats['total_size_mb'] = round(stats['total_size_bytes'] / (1024 * 1024), 2)
        return stats


class VenueCache:
    """
    ä¼šå ´æ¤œç´¢å°‚ç”¨ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ˜ãƒ«ãƒ‘ãƒ¼
    """
    
    def __init__(self, cache_manager: CacheManager):
        self.cache = cache_manager
    
    def get_bigquery_result(self, venue_name: str, location_hints: str = "") -> Optional[Dict]:
        """BigQueryæ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
        cache_key = f"venue_search:{venue_name}:{location_hints}"
        return self.cache.get(cache_key, category="bigquery")
    
    def set_bigquery_result(self, venue_name: str, location_hints: str, result: Dict, ttl: int = 1800) -> None:
        """BigQueryæ¤œç´¢çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ30åˆ†ï¼‰"""
        cache_key = f"venue_search:{venue_name}:{location_hints}"
        self.cache.set(cache_key, result, category="bigquery", ttl=ttl)
    
    def get_places_api_result(self, venue_name: str, location: str) -> Optional[Dict]:
        """Places APIæ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
        cache_key = f"places_search:{venue_name}:{location}"
        return self.cache.get(cache_key, category="places_api")
    
    def set_places_api_result(self, venue_name: str, location: str, result: Dict, ttl: int = 3600) -> None:
        """Places APIæ¤œç´¢çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ1æ™‚é–“ï¼‰"""
        cache_key = f"places_search:{venue_name}:{location}"
        self.cache.set(cache_key, result, category="places_api", ttl=ttl)
    
    def get_venue_detail(self, place_id: str) -> Optional[Dict]:
        """ä¼šå ´è©³ç´°æƒ…å ±ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
        return self.cache.get(place_id, category="venue_detail")
    
    def set_venue_detail(self, place_id: str, result: Dict, ttl: int = 7200) -> None:
        """ä¼šå ´è©³ç´°æƒ…å ±ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ2æ™‚é–“ï¼‰"""
        self.cache.set(place_id, result, category="venue_detail", ttl=ttl)


class GeminiCache:
    """
    Geminiåˆ†æå°‚ç”¨ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ˜ãƒ«ãƒ‘ãƒ¼
    """
    
    def __init__(self, cache_manager: CacheManager):
        self.cache = cache_manager
    
    def get_analysis_result(self, image_path: str) -> Optional[Dict]:
        """ç”»åƒåˆ†æçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–å¾—"""
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ™‚é–“ã¨ã‚µã‚¤ã‚ºã‚’å«ã‚ã¦ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        try:
            if os.path.exists(image_path):
                stat = os.stat(image_path)
                cache_key = f"{image_path}:{stat.st_mtime}:{stat.st_size}"
            else:
                # URLã®å ´åˆ
                cache_key = image_path
            
            return self.cache.get(cache_key, category="gemini")
        except Exception:
            return None
    
    def set_analysis_result(self, image_path: str, result: Dict, ttl: int = 86400) -> None:
        """ç”»åƒåˆ†æçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆ24æ™‚é–“ï¼‰"""
        try:
            if os.path.exists(image_path):
                stat = os.stat(image_path)
                cache_key = f"{image_path}:{stat.st_mtime}:{stat.st_size}"
            else:
                # URLã®å ´åˆ
                cache_key = image_path
            
            self.cache.set(cache_key, result, category="gemini", ttl=ttl)
        except Exception as e:
            print(f"âš ï¸ Failed to cache Gemini result: {e}")


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹
    cache = CacheManager("cache", default_ttl=3600)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    cache.set("test_key", {"data": "test_value"}, category="test")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    result = cache.get("test_key", category="test")
    print(f"Retrieved: {result}")
    
    # çµ±è¨ˆæƒ…å ±
    stats = cache.get_stats()
    print(f"Cache stats: {stats}")
    
    # ä¼šå ´ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä½¿ç”¨ä¾‹
    venue_cache = VenueCache(cache)
    venue_cache.set_bigquery_result("test_venue", "Tokyo", {"place_id": "test123"})
    cached_venue = venue_cache.get_bigquery_result("test_venue", "Tokyo")
    print(f"Cached venue: {cached_venue}")